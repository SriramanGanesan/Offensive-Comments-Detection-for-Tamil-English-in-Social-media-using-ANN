{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6a9aa83-9629-4085-a935-14925f793516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.39.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: pyspellchecker in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: emoji in c:\\users\\sriraman\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.10.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FFBEDA2170>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/emoji/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FFBEDA2050>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/emoji/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FFBEDA2830>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/emoji/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FFBEDA2C80>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/emoji/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001FFBEDA2E30>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/emoji/\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install pyspellchecker\n",
    "!pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f1c703-9ab1-4695-892f-4a404b90f8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from huggingface_hub import notebook_login\n",
    "from spellchecker import SpellChecker\n",
    "from datasets import load_dataset\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "808ce122-5e9b-436f-a23f-9beabf72aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3861 1207\n"
     ]
    }
   ],
   "source": [
    "eng_tam_train_dataset1 = load_dataset(\"csv\", data_files=\"eng_tam_3_train.tsv\", sep=\"\\t\")\n",
    "eng_tam_train1 = eng_tam_train_dataset1[\"train\"]\n",
    "eng_tam_test_dataset1 = load_dataset(\"csv\", data_files=\"eng_tam_3_test.tsv\", sep=\"\\t\")\n",
    "eng_tam_test1 = eng_tam_test_dataset1[\"train\"]\n",
    "print(len(eng_tam_train1), len(eng_tam_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b238edbb-5769-4d2b-afb6-3e9d79493450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['category', 'text', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'],\n",
       "     num_rows: 3861\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['category', 'text', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19'],\n",
       "     num_rows: 1207\n",
       " }))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tam_train1, eng_tam_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ff0528-950e-4ba5-b93d-ca9aac3433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unnamed colum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e015343a-e469-4fef-8d98-c2663bf2f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tam_train1 = eng_tam_train1.remove_columns(column_names=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', \n",
    "                                       'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15'\n",
    "                                       , 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21'\n",
    "                                       , 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27'])\n",
    "eng_tam_train1 = eng_tam_train1.rename_column(original_column_name= 'category', new_column_name= 'label')\n",
    "eng_tam_train1 = eng_tam_train1.class_encode_column(column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06e988a4-3856-4308-aca5-7789e610ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_tam_test1 = eng_tam_test1.remove_columns(column_names=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', \n",
    "                                       'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15'\n",
    "                                       , 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19'])\n",
    "eng_tam_test1 = eng_tam_test1.rename_column(original_column_name= 'category', new_column_name= 'label')\n",
    "eng_tam_test1 = eng_tam_test1.class_encode_column(column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc4e405-0a7a-4a74-bd5a-e3d4217663f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['label', 'text'],\n",
       "     num_rows: 3861\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['label', 'text'],\n",
       "     num_rows: 1207\n",
       " }))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tam_train1,  eng_tam_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0b2df0-53fe-46f4-91c2-7650946780ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting datasets into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd22bd18-1145-4a13-a624-a84861ac41ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kadhayalla Nijam¬† thaa gay Punda Apo ne confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>love you  too Nanba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Semma super üëçüëçüëçüëç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ava ka elom kadavuluka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Bro gay persons kalyanam panninaa kozhanda pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>1</td>\n",
       "      <td>Antha akka romba caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>1</td>\n",
       "      <td>@Dan_Lei¬†  Nii Pooi Vidurayaa  Unakku Yaarum v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>1</td>\n",
       "      <td>Frnds neenga antha yedathula a irrunthaalum am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking pretty ü§©</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>1</td>\n",
       "      <td>Apadi kai vekkumbothu kevalama yevono thittita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3861 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  @Kadhayalla Nijam¬† thaa gay Punda Apo ne confi...\n",
       "1         1                                love you  too Nanba\n",
       "2         1                                   Semma super üëçüëçüëçüëç\n",
       "3         1                             Ava ka elom kadavuluka\n",
       "4         1  Bro gay persons kalyanam panninaa kozhanda pet...\n",
       "...     ...                                                ...\n",
       "3856      1                            Antha akka romba caring\n",
       "3857      1  @Dan_Lei¬†  Nii Pooi Vidurayaa  Unakku Yaarum v...\n",
       "3858      1  Frnds neenga antha yedathula a irrunthaalum am...\n",
       "3859      1                                   Looking pretty ü§©\n",
       "3860      1  Apadi kai vekkumbothu kevalama yevono thittita...\n",
       "\n",
       "[3861 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tam_train1.set_format(type=\"pandas\")\n",
    "eng_tam_test1.set_format(type=\"pandas\")\n",
    "\n",
    "df_eng_tam_train1 = eng_tam_train1[:]\n",
    "df_eng_tam_test1 = eng_tam_test1[:]\n",
    "\n",
    "df_eng_tam_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a0a32-c3f8-4847-a531-de29e59d55d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e6e9cad-30b3-4150-8edb-306d863eb8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_tam_train1 = df_eng_tam_train1.dropna()\n",
    "df_eng_tam_test1 = df_eng_tam_test1.dropna()\n",
    "\n",
    "df_eng_tam_train1 = df_eng_tam_train1.reset_index(drop=True)\n",
    "df_eng_tam_test1 = df_eng_tam_test1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b472c582-97c5-4e67-881c-02c15f7a854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Non Preprocessed and Non Augumented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6755083e-97ce-4cbb-bc3d-346cec6e2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_tam_train1.to_csv('eng_tam_train_nonprepro.csv', index=False)\n",
    "df_eng_tam_test1.to_csv('eng_tam_test_nonprepro.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e544ea20-0176-4089-9136-63f5ba03a6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d848d631-dba2-41f2-8790-bd16aa1af913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emoji\n",
    "df_eng_tam_train1['text'] = df_eng_tam_train1['text'].apply(lambda x: emoji.demojize(x, delimiters=(\" \", \" \")))\n",
    "df_eng_tam_test1['text'] = df_eng_tam_test1['text'].apply(lambda x: emoji.demojize(x, delimiters=(\" \", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d96277c-876c-4fce-9c9a-86f9734244e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kadhayalla Nijam¬† thaa gay Punda Apo ne confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>love you  too Nanba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Semma super  thumbs_up  thumbs_up  thumbs_up  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Ava ka elom kadavuluka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Bro gay persons kalyanam panninaa kozhanda pet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3856</th>\n",
       "      <td>1</td>\n",
       "      <td>Antha akka romba caring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>1</td>\n",
       "      <td>@Dan_Lei¬†  Nii Pooi Vidurayaa  Unakku Yaarum v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>1</td>\n",
       "      <td>Frnds neenga antha yedathula a irrunthaalum am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>1</td>\n",
       "      <td>Looking pretty  star-struck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>1</td>\n",
       "      <td>Apadi kai vekkumbothu kevalama yevono thittita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3861 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         0  @Kadhayalla Nijam¬† thaa gay Punda Apo ne confi...\n",
       "1         1                                love you  too Nanba\n",
       "2         1  Semma super  thumbs_up  thumbs_up  thumbs_up  ...\n",
       "3         1                             Ava ka elom kadavuluka\n",
       "4         1  Bro gay persons kalyanam panninaa kozhanda pet...\n",
       "...     ...                                                ...\n",
       "3856      1                            Antha akka romba caring\n",
       "3857      1  @Dan_Lei¬†  Nii Pooi Vidurayaa  Unakku Yaarum v...\n",
       "3858      1  Frnds neenga antha yedathula a irrunthaalum am...\n",
       "3859      1                       Looking pretty  star-struck \n",
       "3860      1  Apadi kai vekkumbothu kevalama yevono thittita...\n",
       "\n",
       "[3861 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng_tam_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9318ec3-3b7a-4994-8f98-8ddda9502bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "462dc684-7a20-484c-afa0-1d1e16125e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_tok = Tokenizer(split=' ', lower=True, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "train_text_tok.fit_on_texts(df_eng_tam_train1['text'])\n",
    "\n",
    "test_text_tok = Tokenizer(split=' ', lower=True, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "test_text_tok.fit_on_texts(df_eng_tam_test1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed8b5f-f246-4433-b5f5-208b0729371d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3448ba30-9fc0-41e3-a802-be4bab75048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = train_text_tok.texts_to_sequences(df_eng_tam_train1['text'])\n",
    "\n",
    "df_eng_tam_train1['text'] = df_eng_tam_train1.apply(lambda row: train_text_tok.sequences_to_texts([train_tok[row.name]])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d29c40-6d86-4cb8-8873-9ed6b6a90171",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tok = test_text_tok.texts_to_sequences(df_eng_tam_test1['text'])\n",
    "\n",
    "df_eng_tam_test1['text'] = df_eng_tam_test1.apply(lambda row: test_text_tok.sequences_to_texts([test_tok[row.name]])[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7817a-55ac-4dbd-a79e-428f4c7e09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running spell check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfcb73a3-b609-4a4f-a072-e65699712544",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "spell.word_frequency.load_words(['lgbt', 'lgbtq', 'lgbtqia+', 'gay', 'lesbian', 'transgender', 'trans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6db63013-87d0-42df-a5a8-38da68f8e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check(row):\n",
    "    correct_sent = []\n",
    "    misspelled = spell.unknown(row.split())\n",
    "    for word in row.split():\n",
    "        correction = spell.correction(word)\n",
    "        if correction is not None:\n",
    "            correct_sent.append(correction)\n",
    "        else:\n",
    "            correct_sent.append(word)\n",
    "\n",
    "    return \" \".join(correct_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd6f9a-8e1e-4a28-a427-ee6a9c3cad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_tam_train1['text'] = df_eng_tam_train1['text'].apply(spell_check)\n",
    "df_eng_tam_test1['text'] =df_eng_tam_test1['text'].apply(spell_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d016ca6-0cd4-4261-9650-0e6b4208f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_tam_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40653372-d7ab-4108-8bdf-faa93ebcbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ac563-6d8f-49f6-9363-1bd2af67ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng_tam_train1.to_csv('eng_tam_train_prepro.csv', index=False)\n",
    "df_eng_tam_test1.to_csv('eng_tam_test_prepro.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f394f-568e-42eb-8755-63c66f643190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
